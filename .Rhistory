library(readxl)
# Set the directory path
dir_path <- "G:/R_project/CIS7031/DataSet/Plan"
# Get a list of all files in the directory
file_list <- list.files(dir_path)
# Create an empty data frame to store the combined data
combined_data <- data.frame()
# Loop through each file in the list
for (i in seq_along(file_list)) {
# Check if the file name starts with ~$
if (!startsWith(file_list[i], "~$")) {
# Read the file into a data frame
file_data <- read_excel(paste0(dir_path, "/", file_list[i]))
section <- ceiling(i / 12)
# Add a new column called "Section" with a value based on the file number
section <- ifelse(i <= 12, 1, ifelse(i <= 24, 2, ifelse(i <= 36, 3, 4)))
file_data$Section <- section
# Print the name of the dataset being combined
cat("Combining", file_list[i], "into section", section, "\n")
# Combine the data with the existing data frame
combined_data <- rbind(combined_data, file_data)
} else {
# Print a message indicating that the file was skipped
cat("Skipping temporary file:", file_list[i], "\n")
}
}
# Print the combined data
print(combined_data)
#dataset called LC Sec 1 - 06.18 - 06.29 is removed since missing columns: Eff. %	Qty.	Cum Qty.	Standard Hours.	Cum.Standard Hours.	Work Hours.	Cum.Work Hours.
# Set the file path for the CSV file
file_path <- "G:/R_project/CodeBase/RAssignment/combined_data.csv"
# Write the data frame to a CSV file
write.csv(combined_data, file_path, row.names = FALSE)
# Print a message indicating that the file has been saved
cat("The combined data has been saved as", file_path, "\n")
# Print information about the structure of the combined_data data frame
str(combined_data)
# Print the unique values of each column in the combined_data data frame
cat("Unique values of each column:\n")
for (col_name in colnames(combined_data)) {
cat(col_name, ":", length(unique(combined_data[[col_name]])), "unique values\n")
}
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(combined_data))
for (i in seq_along(na_count)) {
cat(colnames(combined_data)[i], ":", na_count[i], "NA values\n")
}
# Drop rows with NA values in "S/O" and "L/I" columns
combined_data <- combined_data[complete.cases(combined_data[, c("S/O", "L/I")]), ]
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(combined_data))
for (i in seq_along(na_count)) {
cat(colnames(combined_data)[i], ":", na_count[i], "NA values\n")
}
#Actual Production Details
# PR 01.24.2018 - D051 Dataset was removed
# set the directory path where the Excel files are located
dir_path <- "G:/R_project/CIS7031/DataSet/Production Quantities"
# get the list of all Excel files in the directory
file_list <- list.files(dir_path, pattern = "\\.xlsx$", full.names = TRUE)
# create an empty list to store the data frames
df_list <- list()
# loop through each Excel file and read the required columns
for (i in seq_along(file_list)) {
# read the Excel file
temp_df <- readxl::read_excel(file_list[i], sheet = 1)
# Print the name of the dataset being combined
cat("Combining", file_list[i])
# subset the required columns
temp_df <- temp_df[, c("Date","Section","PE","Work Center","Module","Worked Hours","Customer","Style Code","SO","LI","FG Reference","SO/LI Worked Hours","Efficiency","Total","SMV","Standard Hours")]
# coerce the SO and LI columns to character type
temp_df$SO <- as.character(temp_df$SO)
temp_df$LI <- as.character(temp_df$LI)
# add a new column for the file name
temp_df$File <- basename(file_list[i])
# add the data frame to the list
df_list[[i]] <- temp_df
}
# combine all the data frames into a single data frame
combined_data_ac <- dplyr::bind_rows(df_list)
# Print information about the structure of the combined_data data frame
str(combined_data_ac)
# Print the unique values of each column in the combined_data data frame
cat("Unique values of each column:\n")
for (col_name in colnames(combined_data_ac)) {
cat(col_name, ":", length(unique(combined_data_ac[[col_name]])), "unique values\n")
}
unique_sections <- unique(combined_data_ac$Section)
print(unique_sections)
# get the frequency count of each unique value in the "Section" column
section_freq <- table(combined_data_ac$Section)
# print the frequency count
print(section_freq)
library(dplyr)
# remove the entries with specified values in the Section column
combined_data_ac_filtered <- combined_data_ac %>%
filter(!Section %in% c("Hybrid","PDC SECTION","SECTION X","SEWING","UNION APPAREL"))
# print the unique values of the Section column
unique_sections <- unique(combined_data_ac_filtered$Section)
print(unique_sections)
# print the frequency of each unique value in the Section column
freq_table <- table(combined_data_ac_filtered$Section)
print(freq_table)
library(dplyr)
# create a lookup table to map old values to new values
section_map <- c("SECTION 1" = "1", "SECTION 2" = "2", "SECTION 3" = "3", "SECTION 4" = "4")
# update the values in the Section column
combined_data_ac_filtered <- combined_data_ac_filtered %>%
mutate(Section = section_map[Section])
col_list <- names(combined_data_ac_filtered)
print(col_list)
col_list <- names(combined_data)
print(col_list)
# read the CSV file
combined_data_ac_filtered <- read.csv("G:/R_project/CodeBase/RAssignment/combined_data_ac_filtered.csv")
# change the column names
colnames(combined_data_ac_filtered) <- c("Date", "Section", "PE", "Work Center", "Actual Module", "Actual Worked Hours", "Customer", "Style Code", "SO", "LI", "FG Reference", "SO/LI Worked Hours", "Actual Efficiency", "Total", "Actual SMV", "Actual Standard Hours")
# read the CSV file
combined_data <- read.csv("G:/R_project/CodeBase/RAssignment/combined_data.csv")
# change the column names
colnames(combined_data) <- c("Plan Module","Material","Customer No","Description","Customer Dept","Gender","SO","LI","Order No","Order Qty","Emp","Plan SMV","Date","Plan Efficiency","Qty","Cum Qty","Standard Hours","Cum.Standard Hours","Work Hours","Cum.Work Hours","Section")
# Count the number of NA values in each column of the combined_data_ac_filtered data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(combined_data_ac_filtered))
for (i in seq_along(na_count)) {
cat(colnames(combined_data_ac_filtered)[i], ":", na_count[i], "NA values\n")
}
# remove rows with NULLs in SO and LI columns
combined_data_ac_filtered <- combined_data_ac_filtered[complete.cases(combined_data_ac_filtered[, c("SO", "LI")]), ]
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(combined_data_ac_filtered))
for (i in seq_along(na_count)) {
cat(colnames(combined_data_ac_filtered)[i], ":", na_count[i], "NA values\n")
}
library(tidyr)
# Replace NULL values with the most common value in Style Code column
most_common_style_code <- names(sort(table(combined_data_ac_filtered$`Style Code`), decreasing = TRUE))[1]
combined_data_ac_filtered$`Style Code`[is.na(combined_data_ac_filtered$`Style Code`)] <- most_common_style_code
# Replace NULL values with the most common value in FG Reference column
most_common_fg_reference <- names(sort(table(combined_data_ac_filtered$`FG Reference`), decreasing = TRUE))[1]
combined_data_ac_filtered$`FG Reference`[is.na(combined_data_ac_filtered$`FG Reference`)] <- most_common_fg_reference
# Replace NULL values with the most common value in Actual Efficiency column
most_common_actual_efficiency <- names(sort(table(combined_data_ac_filtered$`Actual Efficiency`), decreasing = TRUE))[1]
combined_data_ac_filtered$`Actual Efficiency`[is.na(combined_data_ac_filtered$`Actual Efficiency`)] <- most_common_actual_efficiency
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(combined_data_ac_filtered))
for (i in seq_along(na_count)) {
cat(colnames(combined_data_ac_filtered)[i], ":", na_count[i], "NA values\n")
}
library(dplyr)
# remove the entries with specified values in the Section column
combined_data_ac_filtered <- combined_data_ac %>%
filter(!Section %in% c("Hybrid","PDC SECTION","SECTION X","SEWING","UNION APPAREL"))
# print the unique values of the Section column
unique_sections <- unique(combined_data_ac_filtered$Section)
print(unique_sections)
# print the frequency of each unique value in the Section column
freq_table <- table(combined_data_ac_filtered$Section)
print(freq_table)
library(dplyr)
# create a lookup table to map old values to new values
section_map <- c("SECTION 1" = "1", "SECTION 2" = "2", "SECTION 3" = "3", "SECTION 4" = "4")
# update the values in the Section column
combined_data_ac_filtered <- combined_data_ac_filtered %>%
mutate(Section = section_map[Section])
# Set the file path for the CSV file
file_path <- "G:/R_project/CodeBase/RAssignment/combined_data_ac_filtered.csv"
# Write the data frame to a CSV file
write.csv(combined_data_ac_filtered, file_path, row.names = FALSE)
# Print a message indicating that the file has been saved
cat("The combined data actual filtered has been saved as", file_path, "\n")
col_list <- names(combined_data_ac_filtered)
print(col_list)
col_list <- names(combined_data)
print(col_list)
# read the CSV file
combined_data_ac_filtered <- read.csv("G:/R_project/CodeBase/RAssignment/combined_data_ac_filtered.csv")
# change the column names
colnames(combined_data_ac_filtered) <- c("Date", "Section", "PE", "Work Center", "Actual Module", "Actual Worked Hours", "Customer", "Style Code", "SO", "LI", "FG Reference", "SO/LI Worked Hours", "Actual Efficiency", "Total", "Actual SMV", "Actual Standard Hours")
# read the CSV file
combined_data <- read.csv("G:/R_project/CodeBase/RAssignment/combined_data.csv")
# change the column names
colnames(combined_data) <- c("Plan Module","Material","Customer No","Description","Customer Dept","Gender","SO","LI","Order No","Order Qty","Emp","Plan SMV","Date","Plan Efficiency","Qty","Cum Qty","Standard Hours","Cum.Standard Hours","Work Hours","Cum.Work Hours","Section")
# Count the number of NA values in each column of the combined_data_ac_filtered data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(combined_data_ac_filtered))
for (i in seq_along(na_count)) {
cat(colnames(combined_data_ac_filtered)[i], ":", na_count[i], "NA values\n")
}
# remove rows with NULLs in SO and LI columns
combined_data_ac_filtered <- combined_data_ac_filtered[complete.cases(combined_data_ac_filtered[, c("SO", "LI")]), ]
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(combined_data_ac_filtered))
for (i in seq_along(na_count)) {
cat(colnames(combined_data_ac_filtered)[i], ":", na_count[i], "NA values\n")
}
library(tidyr)
# Replace NULL values with the most common value in Style Code column
most_common_style_code <- names(sort(table(combined_data_ac_filtered$`Style Code`), decreasing = TRUE))[1]
combined_data_ac_filtered$`Style Code`[is.na(combined_data_ac_filtered$`Style Code`)] <- most_common_style_code
# Replace NULL values with the most common value in FG Reference column
most_common_fg_reference <- names(sort(table(combined_data_ac_filtered$`FG Reference`), decreasing = TRUE))[1]
combined_data_ac_filtered$`FG Reference`[is.na(combined_data_ac_filtered$`FG Reference`)] <- most_common_fg_reference
# Replace NULL values with the most common value in Actual Efficiency column
most_common_actual_efficiency <- names(sort(table(combined_data_ac_filtered$`Actual Efficiency`), decreasing = TRUE))[1]
combined_data_ac_filtered$`Actual Efficiency`[is.na(combined_data_ac_filtered$`Actual Efficiency`)] <- most_common_actual_efficiency
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(combined_data_ac_filtered))
for (i in seq_along(na_count)) {
cat(colnames(combined_data_ac_filtered)[i], ":", na_count[i], "NA values\n")
}
# Set the file path for the CSV file
file_path <- "G:/R_project/CodeBase/RAssignment/actual.csv"
# Write the data frame to a CSV file
write.csv(combined_data_ac_filtered, file_path, row.names = FALSE)
# Print a message indicating that the file has been saved
cat("The actual dataset has been saved as", file_path, "\n")
# Set the file path for the CSV file
file_path <- "G:/R_project/CodeBase/RAssignment/plan.csv"
# Write the data frame to a CSV file
write.csv(combined_data, file_path, row.names = FALSE)
# Print a message indicating that the file has been saved
cat("The plan has been saved as", file_path, "\n")
# read the CSV file
plan <- read.csv("G:/R_project/CodeBase/RAssignment/plan.csv")
# read the CSV file
actual <- read.csv("G:/R_project/CodeBase/RAssignment/actual.csv")
# Check if there are any duplicate rows
any(duplicated(actual))
# Check if there are any duplicate rows
any(duplicated(plan))
# Identify the primary key
duplicated_rows <- duplicated(actual, fromLast = TRUE)
if (any(duplicated_rows)) {
duplicate_indices <- which(duplicated_rows)
primary_key_columns <- c("SO", "LI") # Replace with actual primary key columns
differing_columns <- lapply(duplicate_indices, function(i) {
which(actual[i,] != actual[i+1,])
})
primary_key <- unique(primary_key_columns[c(unlist(differing_columns))])
print(paste("Primary key columns:", paste(primary_key, collapse = ", ")))
} else {
print("No duplicates found")
}
# Identify the primary key
duplicated_rows <- duplicated(plan, fromLast = TRUE)
if (any(duplicated_rows)) {
duplicate_indices <- which(duplicated_rows)
primary_key_columns <- c("SO", "LI") # Replace with actual primary key columns
differing_columns <- lapply(duplicate_indices, function(i) {
which(plan[i,] != plan[i+1,])
})
primary_key <- unique(primary_key_columns[c(unlist(differing_columns))])
print(paste("Primary key columns:", paste(primary_key, collapse = ", ")))
} else {
print("No duplicates found")
}
library(dplyr)
# join the two data frames
joined_data <- left_join(plan, actual, by = c("SO","LI"))
# check the structure of the joined data frame
str(joined_data)
str(joined_data)
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(joined_data))
for (i in seq_along(na_count)) {
cat(colnames(joined_data)[i], ":", na_count[i], "NA values\n")
}
# remove rows with NULLs in SO and LI columns
joined_data <- joined_data[complete.cases(joined_data[, c("Actual.Efficiency")]), ]
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(joined_data))
for (i in seq_along(na_count)) {
cat(colnames(joined_data)[i], ":", na_count[i], "NA values\n")
}
# read the CSV file
join <- read.csv("G:/R_project/CodeBase/RAssignment/join.csv")
col_list <- names(join)
print(col_list)
# change the column names
colnames(join) <- c("Plan.Module","Material","Customer.No","Description","Customer.Dept","Gender","SO","LI","Order.No","Order.Qty","Emp","Plan.SMV","Plan.Date","Plan.Efficiency","Qty","Cum.Qty","Standard.Hours","Cum.Standard.Hours","Work.Hours","Cum.Work.Hours","Plan.Section","Actual.Date","Actual.Section","PE","Work.Center","Actual.Module","Actual.Worked.Hours","Customer","Style.Code","FG.Reference","SO.LI.Worked.Hours","Actual.Efficiency","Total","Actual.SMV","Actual.Standard.Hours")
library(dplyr)
# join the two data frames
joined_data <- left_join(plan, actual, by = c("SO","LI"))
# check the structure of the joined data frame
str(joined_data)
str(joined_data)
# Count the number of NA values in each column of the combined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(joined_data))
for (i in seq_along(na_count)) {
cat(colnames(joined_data)[i], ":", na_count[i], "NA values\n")
}
# remove rows with NULLs in SO and LI columns
joined_data <- joined_data[complete.cases(joined_data[, c("Actual.Efficiency")]), ]
# Count the number of NA values in each column of the joined_data data frame
cat("Number of NA values in each column:\n")
na_count <- colSums(is.na(joined_data))
for (i in seq_along(na_count)) {
cat(colnames(joined_data)[i], ":", na_count[i], "NA values\n")
}
col_list <- names(join)
print(col_list)
# change the column names
colnames(join) <- c("Plan.Module","Material","Customer.No","Description","Customer.Dept","Gender","SO","LI","Order.No","Order.Qty","Emp","Plan.SMV","Plan.Date","Plan.Efficiency","Qty","Cum.Qty","Standard.Hours","Cum.Standard.Hours","Work.Hours","Cum.Work.Hours","Plan.Section","Actual.Date","Actual.Section","PE","Work.Center","Actual.Module","Actual.Worked.Hours","Customer","Style.Code","FG.Reference","SO.LI.Worked.Hours","Actual.Efficiency","Total","Actual.SMV","Actual.Standard.Hours")
join <- joined_data
# change the column names
colnames(join) <- c("Plan.Module","Material","Customer.No","Description","Customer.Dept","Gender","SO","LI","Order.No","Order.Qty","Emp","Plan.SMV","Plan.Date","Plan.Efficiency","Qty","Cum.Qty","Standard.Hours","Cum.Standard.Hours","Work.Hours","Cum.Work.Hours","Plan.Section","Actual.Date","Actual.Section","PE","Work.Center","Actual.Module","Actual.Worked.Hours","Customer","Style.Code","FG.Reference","SO.LI.Worked.Hours","Actual.Efficiency","Total","Actual.SMV","Actual.Standard.Hours")
identical_cols <- c()
for (i in 1:(ncol(join)-1)) {
for (j in (i+1):ncol(join)) {
if (identical(join[,i], join[,j])) {
identical_cols <- c(identical_cols, names(join[i]))
break
}
}
}
print(identical_cols)
# create an empty list to store the identical columns
identical_cols <- list()
# loop through all column combinations and find identical columns
for (i in seq_along(join)) {
for (j in seq_along(join)) {
# only compare different columns
if (i != j) {
# check if columns have identical values and order
if (identical(join[[i]], join[[j]])) {
# add the column names to the list
identical_cols[[length(identical_cols) + 1]] <- c(names(join)[i], names(join)[j])
}
}
}
}
# print the list of identical columns
identical_cols
# remove the Work.Center column from the join dataframe
join <- dplyr::select(join, -Work.Center)
# remove the Work.Center column from the join dataframe
join <- dplyr::select(join, -Work.Center)
# read the CSV file
join <- read.csv("G:/R_project/CodeBase/RAssignment/join.csv")
# get the data types of each column
col_types <- sapply(join, class)
# identify categorical columns as those with "factor" or "character" data types
cat_cols <- names(col_types[col_types %in% c("factor", "character")])
# identify numerical columns as those with "integer" or "numeric" data types
num_cols <- names(col_types[col_types %in% c("integer", "numeric")])
# print the list of categorical columns and numerical columns
cat_cols
num_cols
library(dplyr)
join <- join %>%
mutate(LI = as.factor(LI),
Order.No = as.factor(Order.No))
str(join)
# Print the unique values of each column in the combined_data data frame
cat("Unique values of each column:\n")
for (col_name in colnames(join)) {
cat(col_name, ":", length(unique(join[[col_name]])), "unique values\n")
}
str(join)
library(caret)
library(keras)
library(randomForest)
# Assuming your target variable is Actual.Efficiency
y <- join$Actual.Efficiency
# Remove target variable from input data
X <- join[, !(names(join) %in% "Actual.Efficiency")]
# Identify categorical variables
categorical_cols <- names(X)[sapply(X, is.factor)]
# Convert categorical variables to numerical variables using entity embeddings
embed_input <- list()
input <- list()
for (col in categorical_cols) {
x_in <- layer_input(shape = 1, name = col)
vocab <- unique(X[[col]])
n_factors <- min(50, length(vocab) %/% 2)
x_embed <- x_in %>%
layer_embedding(input_dim = length(vocab), output_dim = n_factors, name = paste0(col, "_embed")) %>%
layer_flatten()
input[[col]] <- x_in
embed_input[[col]] <- x_embed
}
library(caret)
library(keras)
library(randomForest)
# Assuming your target variable is Actual.Efficiency
y <- join$Actual.Efficiency
# Remove target variable from input data
X <- join[, !(names(join) %in% "Actual.Efficiency")]
# Specify categorical columns
categorical_cols <- c("Plan.Module", "Material", "Customer.No", "Description", "Customer.Dept", "Gender",
"SO", "Plan.Date", "Actual.Date", "PE", "Actual.Module", "Customer", "Style.Code",
"FG.Reference", "LI", "Order.No", "Plan.Section", "Actual.Section")
# Convert specified columns to character variables
X[c("LI", "Order.No", "Plan.Section", "Actual.Section")] <- lapply(X[c("LI", "Order.No", "Plan.Section", "Actual.Section")], as.character)
# Convert categorical variables to count-encoded variables
count_encoded_cols <- list()
for (col in categorical_cols) {
counts <- table(X[[col]])
count_encoded <- counts[X[[col]]]
count_encoded_cols[[col]] <- count_encoded
}
# Combine count-encoded variables with numerical columns
count_encoded_X <- do.call(cbind, count_encoded_cols)
num_cols <- names(X)[!names(X) %in% categorical_cols]
num_X <- X[, num_cols]
X <- cbind(count_encoded_X, num_X)
# Fit random forest model
set.seed(123)
rf_model <- randomForest(X, y, importance = TRUE)
library(caret)
library(keras)
library(randomForest)
# Assuming your target variable is Actual.Efficiency
y <- join$Actual.Efficiency
# Remove target variable from input data
X <- join[, !(names(join) %in% "Actual.Efficiency")]
# Specify categorical columns
categorical_cols <- c("Plan.Module", "Material", "Customer.No", "Description", "Customer.Dept", "Gender",
"SO", "Plan.Date", "Actual.Date", "PE", "Actual.Module", "Customer", "Style.Code",
"FG.Reference", "LI", "Order.No", "Plan.Section", "Actual.Section")
# Convert specified columns to character variables
X[c("LI", "Order.No", "Plan.Section", "Actual.Section")] <- lapply(X[c("LI", "Order.No", "Plan.Section", "Actual.Section")], as.character)
# Convert categorical variables to count-encoded variables
count_encoded_cols <- list()
for (col in categorical_cols) {
counts <- table(X[[col]])
count_encoded <- counts[X[[col]]]
count_encoded_cols[[col]] <- count_encoded
}
# Combine count-encoded variables with numerical columns
count_encoded_X <- do.call(cbind, count_encoded_cols)
num_cols <- names(X)[!names(X) %in% categorical_cols]
num_X <- X[, num_cols]
X <- cbind(count_encoded_X, num_X)
# Fit random forest model
set.seed(123)
rf_model <- randomForest(X, y, importance = TRUE)
library(caret)
library(keras)
library(randomForest)
# Assuming your target variable is Actual.Efficiency
y <- join$Actual.Efficiency
# Remove target variable from input data
X <- join[, !(names(join) %in% "Actual.Efficiency")]
# Specify categorical columns
categorical_cols <- c("Plan.Module", "Material", "Customer.No", "Description", "Customer.Dept", "Gender",
"SO", "Plan.Date", "Actual.Date", "PE", "Actual.Module", "Customer", "Style.Code",
"FG.Reference", "LI", "Order.No", "Plan.Section", "Actual.Section")
# Convert specified columns to character variables
X[c("LI", "Order.No", "Plan.Section", "Actual.Section")] <- lapply(X[c("LI", "Order.No", "Plan.Section", "Actual.Section")], as.character)
# Convert categorical variables to count-encoded variables
count_encoded_cols <- list()
for (col in categorical_cols) {
counts <- table(X[[col]])
count_encoded <- counts[X[[col]]]
count_encoded_cols[[col]] <- count_encoded
}
# Combine count-encoded variables with numerical columns
count_encoded_X <- do.call(cbind, count_encoded_cols)
num_cols <- names(X)[!names(X) %in% categorical_cols]
num_X <- X[, num_cols]
X <- cbind(count_encoded_X, num_X)
# Fit random forest model
set.seed(123)
rf_model <- randomForest(X, y, importance = TRUE)
# Print variable importance
print(rf_model$importance)
# Sort and print variable importance
sorted_importance_mse <- sort(rf_model$importance[,"%IncMSE"], decreasing = TRUE)
sorted_importance_nodepurity <- sort(rf_model$importance[,"IncNodePurity"], decreasing = TRUE)
print("Variable Importance - %IncMSE:")
print(sorted_importance_mse)
print("Variable Importance - IncNodePurity:")
print(sorted_importance_nodepurity)
# Get the top 17 columns from sorted_importance_mse and sorted_importance_nodepurity
top_columns_mse <- names(sorted_importance_mse)[1:17]
top_columns_nodepurity <- names(sorted_importance_nodepurity)[1:17]
# Get the union of the top columns
top_columns_union <- union(top_columns_mse, top_columns_nodepurity)
print(top_columns_union)
str(top_features)
# Print the unique values of each column in the combined_data data frame
cat("Unique values of each column:\n")
for (col_name in colnames(top_features)) {
cat(col_name, ":", length(unique(top_features[[col_name]])), "unique values\n")
}
names(top_features)
str(top_features)
str(top_features)
rmse <-14.35
rmse
#The root mean square error (RMSE) value of 14.34659 indicates the average difference between the predicted values and the actual values of the "Actual.Efficiency" variable in the test dataset. Since the RMSE is a measure of the model's prediction error, a lower RMSE value indicates better performance.
rmse <-3.290157
rmse
rmse <-8.20233
rmse
rmse <-14.34659
rmse
#The root mean square error (RMSE) value of 14.34659 indicates the average difference between the predicted values and the actual values of the "Actual.Efficiency" variable in the test dataset. Since the RMSE is a measure of the model's prediction error, a lower RMSE value indicates better performance.
library(dplyr)
# remove the Work.Center column from the join dataframe
joined_data <- dplyr::select(joined_data, -Work.Center)
